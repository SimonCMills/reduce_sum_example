---
title: "Reduce_sum applied to 2D data"
date: "22 June 2020"
output: bookdown::html_document2
---

In the 2.23 update, Stan introduced ```reduce_sum```, which allows us to parallelise within-chain computation. The 1D case- where the response variable is a vector- has a well worked example ([here](https://mc-stan.org/users/documentation/case-studies/reduce_sum_tutorial.html)), and the speedups for these simple models where most of the computation can be placed inside the parallel sum component are reasonably well documented (though see e.g. Mcelreath post). It's taken a bit of experimentation to figure out how to apply ```reduce_sum``` to a 2D case and I'm not aware of equivalent worked examples for these cases, or example speedups. This document therefore aims to provide a minimal example of a 2D application of ```reduce_sum``` and take a look at some of the speedups.

There is:

1. A brief description of the model and the data structure
2. Fitting this model using ```reduce_sum```
3. A comparison of speedups with increasing #cores

They are referred to at various points throughout, but see also: 

- The ```reduce_sum``` documentation https://mc-stan.org/docs/2_23/stan-users-guide/reduce-sum.html

- [The 1D worked example (logistic regression)](https://mc-stan.org/users/documentation/case-studies/reduce_sum_tutorial.html), which has details that aren't included here. 

- [https://jsocolar.github.io/occupancyModels/](https://jsocolar.github.io/occupancyModels/) as an introduction/explanation to the model in Stan. 

# (Brief) model description
A model familiar to many ecologists is the occupancy model. They come in a lot of flavours, but, very broadly, these models are typically attempting to relate binary presence/absence to characteristics of the environment and/or species, usually using data collected from a number of different spatial locations. 

Of these models a further broad subset are detection-occupancy models, which attempt to delinate observed occupancy into separate detection and occupancy components (i.e. acknowledge that the probability of observing a given species depends both on the underlying probability of presence and also how likely it is to be observed, given presence). In order to do this, two things are required: first there needs to be some form of replicated sampling, and second we need to be able to reasonably assume that if a species is observed on a single one of these replicates, it is 'present' (in some sense) on every other of the replicates. The resulting mixture of 0s and 1s then allow for us to say something about both detection and occupancy. 

We'll take a look at these detection-occupancy models, partly because it is working with these models that have motivated the need to parallelise, due to the fact that these datasets can quickly become large and they aren't obviously reduced to a 1D observation vector for modelling, but also they are also somewhat distinct from different flavours of glm that are already documented. 

These models are readily fit in Stan (note though that they are slightly differently formulated than in JAGS/BUGS, see [here](https://jsocolar.github.io/occupancyModels/)).

## Data simulation
For our simulated species, there is variation in occupancy both across species (i.e. some species are more common than others), and also across an environmental gradient. Across all species, there is an average tendency for occupancy probability to increase across the environmental gradient, but there is variation in the strength of this association across species, such that some species can decrease in occupancy probability along this gradient. Detection varies across species, with some species more readily detected than others, and also with a visit-level covariate, which, for the sake of argument, we'll call time of day. Again, there is an average (negative) time of day effect across species, but species also vary in the strength of this association. 

More formally: 
$$\psi_{ik} = \beta_{0k} + \beta_{1k}.x_i$$
$$\theta_{ijk} = \alpha_{0k} + \alpha_{1k}.t_{ij}$$
$$Z_{ik} \sim bernoulli(logit^{-1}(\psi_{ik}))$$
$$y_{ijk} \sim bernoulli(logit^{-1}(\theta_{ijk}) \times Z)$$

where $\psi_{ik}$ is the occupancy probability, which varies according to a species-level intercept, and a species-level environmental association (where $x_i$ is the environmental variable). $\theta_{ijk}$ is the detection component, and varies according to a species-level intercept, and a species-level time of day effect. All species-level effects are simulated and modelled as normally-distributed random effects, i.e. eight hyperparameters in total.

Data are generated from this model in the following script:
```{r, message=F} 
source("simulate_data.R")
```
For the timings, I'll generate 50 species across 50 sites and 4 visits (i.e. 10,000 observations in total). 

Visually, the model look something like this (for nine example species):
```{r figs, echo=F, fig.align = "center", fig.cap = "Nine example species taken from the full simulation. Solid line indicates the underlying occupancy relationship, while the dashed line indicates the probability of detection, accounting for the species' detectability. As this depends both on the species' detectibility and also a visit-level covariate (time of day), the detectibility is not a constant offset, but rather varies depending on time of day (which varies between 0 and 1). Note the variation in the environmental association, the detection offset, and the strength of the time-of-day effect on detection accross species"}
# plot
df_sim_eg <- expand.grid(i = 1:n_site, 
                         j = 1:n_visit, 
                         k = 1:9,
                         time = c(0, 1)) %>%
    as_tibble %>%
    mutate(env_var = env_var[i], 
           psi = b0[k] + b1[k]*env_var[i], 
           Z = rbinom(n(), 1, inv.logit(psi)), 
           theta = d0[k] + d1[k]*time, 
           det_sim = rbinom(n(), Z, inv.logit(theta)))

ggplot(df_sim_eg, aes(env_var, inv.logit(psi), group=time)) + 
    geom_line() +
    geom_line(aes(y=inv.logit(psi)*inv.logit(theta), col=factor(time)), lty=2) +
    theme(axis.text = element_text(colour="black"),
          strip.text = element_text(hjust=0, face="bold"),
          strip.background = element_blank(),
          panel.grid.minor= element_blank(),
          aspect.ratio=1) +
    ylim(0,1) +
    labs(x="Environmental gradient", y="Probability of occupancy/detection", 
         colour = "Time of day (scaled)") +
    facet_wrap(~k) 
```

## Data structure
Observations inherently have a 3D structure, structured by the point that was surveyed (point $i$), the visit to the point (visit $j$), and the species that was observed/unobserved (species $k$). However, these are readily collapsed to a 2D structure by collapsing the species dimension to produce a dataframe that has dimensions ($n_{points} \times n_{species}$, $n_{visits}$), with each row now indexing a point:species combination. 

```{r, comment=NA}
head(det_sim_wide)
```
We have two columns that identify the species:point combination, followed by 4 columns that give the observation (0 or 1) across each of 4 visits to the point. 

The time of day predictor has the same dimensions. It could be reduced to a smaller [i, j] array, as time of day only depends upon when the point was visited, not upon which species were observed, but it's more straightforward to just produce it as a array of times with the same dimensions as the detection data.  
```{r, comment=NA}
head(time_sim_wide)
```

```{r, comment=NA}
head(env_var)
```
Finally, an environmental variable, that just varies between points. 

# The Stan model
The Stan file is a little complicated if it's not a model you are already familiar with. The main oddity is the if-statement asking if Q==1: this just refers to the central assumption mentioned at the outset, where points that have at least one observation are treated as though the species is present (but undetected) at all other visits. The converse, where a species is never observed at a point is more complicated, because now we have to acknowledge that it might have been there all along, but never observed, and also that it might simply not be there. Again [https://jsocolar.github.io/occupancyModels/](https://jsocolar.github.io/occupancyModels/) explains this in more detail. 

```{r, comment=NA, echo=F}
cat(readLines('occupancy_example.stan'), sep = '\n')
```

# ```reduce_sum``` formulation
To get the parallelisation done, we need to break up the computation such that it can be passed out to multiple workers. To do this, the model itself wrapped in ```partial_sum``` (user-written function), which will allow the full task of calculating all the log-probabilities to be broken up into chunks (the size of which are set by the grainsize argument). ```reduce_sum``` will automate the choice about how to chunk up the data, and pass these data chunks out to be computed in parallel. 

```{r, comment=NA, echo=F}
cat(readLines('occupancy_example_redsum.stan'), sep = '\n')
```

This is largely a repetition of the previous stan model, the only difference is that the model has been shifted into the ```parallel_sum``` function block. Note that a lot of stuff has to get passed to this function: you could simplify it by doing more computation outside (e.g. transforming some parameters) and passing a reduced set of objects, but then you would be shifting more of the computation *outside* of the bit that will be run in parallel. As the parallelisation speedup would take a hit from doing this, it's better to do it this way, despite the unwieldiness of the ensuing function. 

# Timings 

```{r fig2, echo=F, fig.align = "center", fig.cap = "Timings across 1, 2, 4, and 8 cores, using a simulated dataset with 50 species, 50 sites, and 4 visits (i.e. 10,000 observations in total). "}
library(ggplot2)
dat <- data.frame(cpu=c(1, 2, 4, 8), 
                  time = c(1860.0, 801.7, 660.1, 337.7))
dat$bc <- dat$time[1]/dat$cpu
dat$speedup <- round(dat$time[1]/dat$time, 2)
ggplot(dat, aes(log(cpu), log(time))) + geom_point() + geom_line() + 
    # geom_point(data=timings2) +
    # geom_line(data=timings2) +
    # geom_point(data=timings3) +
    # geom_line(data=timings3) +
    scale_x_continuous(breaks=log(dat$cpu), labels=dat$cpu) +
    geom_line(aes(y=log(bc)), lty=2) +
    scale_y_continuous("Log-time (s)", breaks=c(6, 6.5, 7, 7.5), labels = round(exp(c(6, 6.5, 7, 7.5)), 0), 
                       sec.axis = sec_axis(trans = ~dat$time[1]/exp(.), name = "Relative speedup", breaks = c(1, 2, 4, 6, 8))) +
    theme(aspect.ratio=.7, panel.grid.minor = element_blank()) 

```
Timings:
```{r, comment=NA, echo=F}
dat[,-3]
```

As you would hope, we are getting good speedups by parallelising the model. While the dataset simulated here is fairly small, with a larger dataset, a 4-6x speedup on a chain that would otherwise take >1 week to run is not trivial at all! The speedup itself will also depend on the proportion of the model that can be placed within the ```partial_sum``` function (see [here](https://statmodeling.stat.columbia.edu/2020/05/05/easy-within-chain-parallelisation-in-stan/)). With increased model complexity, as long as the relative proportions of 'stuff in the ```partial_sum```' to 'stuff outside the ```partial_sum```' remain constant, we should expect to see similar speedups. Anecdotally this seems to be the case, and I've seen fairly equivalent speedups running these models with more complexity (e.g. more terms in the detection and occupancy components).

For models where almost all the computation can be placed inside the ```partial_sum```, we can achieve a 1:1 speedup (in some cases, marginally better!). Given that this model has a bunch of centering of hyper-parameters outside of the main model block, it is to be expected that we should see speedups slightly below this line. 

The other thing to mention is that when comparing speedups, it's important to give the computer a proper job to really see the speedup from parallelisation. If it only takes 30 seconds to run the model, then the speedups are all over the place (though the tendency to get faster with increasing cores is present). Initially I had been simulating 15 species at 15 sites, across 4 visits (i.e. 900 observations)- speedups were (a) not very repeatable, varying substantially between runs, and (b) the scaling didn't look great. Presumably this largely arises because the overhead paid for parallelising makes up a greater proportion of the total run time, and it's difficult to get large speed-gains on the bit that is being run in parallel. 
